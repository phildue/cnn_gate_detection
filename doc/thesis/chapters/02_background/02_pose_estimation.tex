\section{Pose Estimation}
\label{sec:bg:pose_estimation}
	\subsection{(Re-) Localization}
	\paragraph{PoseNet: A Convolutional Network for Real-Time 6-DOF Camera Relocalization \cite{Kendall}}
	\begin{itemize}
		\item[-] Relocalizes, is trained on images from the scenes where it is applied	\item[-] Accuracy 2m and 3$\degree$  in 50 km$^2$ outdoors, 0.5m and 5$\degree$ indoors, 5ms per frame
		\item[-] ConvNet 23 layers, Image resolution 224x224
		\item[-] transfer learning from recognition/classification datasets (ConvNet is trained on classification tasks)
		\item[-] based on GoogleNet, affine regressors instead of softmax\item[-] automatic training data generation (structure from motion)
		\item[-] learns p from arbitrary global reference frame
		\item[-] $loss(I) = || \hat{x}-x||_2 + \beta*||\hat{q}-\frac{q}{||q||}||_2$
		\item[-] separating position/orientation led to drop in performance
		\item[-] PoseNet evaluation at single center crop + Dense PoseNet 128 uniformly spaced crops (time increase 95ms, only slight accuracy increase)
		\item[-] Training data generated using structure from motion (Cambridge Scene) and 7 Scenes (Microsoft) for indoor
		
	\end{itemize}
	\paragraph{A Deep Learning Based 6 Degree-of-Freedom
		Localization Method for Endoscopic Capsule Robots \cite{Turan2017}}
	\begin{itemize}
		\item[-] not published yet?
		\item[-] Uses 6-DOF camera pose directly
		\item[-] based on GoogleNet (9 Inception modules) trained on ImageNet
		\item[-] $loss(I) = ||\hat{x}-x||_2 + ||\hat{q}-q||_2$
		\item[-] Dataset of 10 000 frames taken from LM103 - EDG (EsophagoGastroDuodenoscopy) Simulator
		\item[-] 0.18cm RMSE on a trajectory of 18cm
		\item[-] Although 3 different cameras are used and the frames are separated for training and testing, its still the same "stomach". With 10 000 frames on a trajectory of 18 cm, won't the system just recognize the position?
		\item[-] Ground truth determined by seperate cameras 
	\end{itemize}
	\subsubsection{Object Pose Estimation}
	\paragraph{3D generic object categorization localization and pose estimation \cite{Savarese}}
	\begin{itemize}
		\item[-] Other approaches use different class for different poses
		\item[-] Object model is separated in different parts of the object based on different view points (front view)
		\item[-] Different parts are connected when another part is visible from the front view via affine transformation
		\item[-] Generally such models can't handle inter class variations very good or increase in complexity as number of parts is increased. In this paper this is apparently not the case
	\end{itemize}
	\paragraph{Uncertainty-Driven 6D Pose Estimation of Objects and Scenes from a Single RGB Image
		Eric \cite{Brachmann}}
	\begin{itemize}
		\item[-] Intermediate representation are object coordinates, continious part labeling that are jointly regressed for every pixel in the image
		\item[-] Based on auto context (Classifiers with several stages)
		\item[-] (1) (Auto context) Random forest with L1 regularization predicts labels and object coordinates for every pixel (2) Ransac predicts poses from 2d-3d correspondences guided by uncertainty labels
		(3) Refinement
		\item[-] Random forest predicts (probability to belong to object + 3d coordinate|given belonging to object)
		\item[-] Stacked Forests (Auto context) refine output on previous smoothed output (Geodesic Forest). The smoothing is done to enforce coupling of neighbors 
		\item[-] RANSAC formulates hypothesis by drawing 4 correspondences and solving PnP
		\item[-] Outperforms PoseNet in indoor localization
		\item[-] 6D within 5cm and 5 degree only 40 \% (With RGB-D 82.5\%), on other set 50 \% with unknown scene average median error 8.5cm 3.3Â°
		\item[-] Biggest translational error in z direction
		\item[-] Multi object detection/pose estimation in 1-4 seconds, not optimized, most time spend in searching for object hypothesis
	\end{itemize}
	\paragraph{A Comparative Analysis and Study of Multiview CNN Models for Joint Object Categorization and Pose Estimation\cite{Elhoseiny}}
	\begin{itemize}
		\item[-] While detection needs pose invariant features, pose estimation needs the pose
		\item[-] Single instance 3d model
		\item[-] Discrete pose approaches (pose as classification)
		\item[-] Trains pose regressor and classifier on output of different levels to measure quality of features
		\item[-] Later layers "forget" about pose, paper suggests early branching
	\end{itemize}
	\subsection{Other}
	\paragraph{Deformable Convolutional Networks \cite{Dai}}
	\begin{itemize}
		\item[-] Addresses problem of modeling geometric transformations
		\item[-] Introduces \textit{Deformable Convolution} which adds 2D offsets to the regular sampling grid. The offsets are learned from the data.
		\item[-] Introduces \textit{Deformable RoI pooling} which adds offsets to bins of pooling layers. The offsets are also learned from the data.
		\item[-] Further alternatives to have more variable feature maps: Spatial Transformer Networks, Active Convolution, Effective Receptive Field, Atrous Convolution, DeepID-Net, Spatial manipulation in RoI pooling (handcrafted), DPM (handcrafted)
		\item[-] Light-weight version of STN, easier to train and to integrate
		\item[-] Receptive fields seem to scale with the size of objects
		\item[-] Model complexity is increased by only 1-2%
	\end{itemize}
	
