	\chapter{Detecting \ac{EWFO} on \ac{MAV}}
	\label{sec:object_detection}
	
	This chapter addresses the detection of \ac{EWFO}. In particular the following research questions are addressed:
	
\begin{enumerate}
	\item[\textbf{RQ2}]What kind of architecture is suitable to detect \acp{EWFO}?
	\item[\textbf{RQ3}]What are the trade-offs in detection performance and inference time when a detection model for \acp{EWFO} is deployed on a \ac{MAV}?
%	\item[\textbf{RQ4}]Can the gained insights be used to build a lightweight and robust detection model for racing gates in the \ac{IROS} Autonomous Drone Race?
\end{enumerate}

	The chapter introduces the model used for this work and conducts several experiments to find a suitable architecture.
	
	\section{Methodology}
	
	A literature review has been conducted in order to find a suitable approach for the detection of \ac{EWFO} on \acp{MAV}. \acp{CNN} achieve currently the best performance however, their drawback is their computational requirements and their need of data. We hypothesize that due to the simplicity of the object it is possible to generate training data using a graphical engine and to simplify the \acp{CNN} architecture to speed up the inference time.
	
	A trade-off between accuracy and inference speed are One-Stage Object Detectors such as \ac{Yolo} and \ac{SSD}. We decide for Yolo as a framework is available that simplifies the implementation on the target platform.
	
	The original training goal is defined as follows:
	\if false
	\begin{align}
	&\lambda_{coord} \sum_{i=0}^{S^2}\sum_{j=0}^B \mathbb{1}_{ij}^{obj}[(x_i-\hat{x}_i)^2 + (y_i-\hat{y}_i)^2 ] \\&+ \lambda_{coord} \sum_{i=0}^{S^2}\sum_{j=0}^B \mathbb{1}_{ij}^{obj}[(\sqrt{w_i}-\sqrt{\hat{w}_i})^2 +(\sqrt{h_i}-\sqrt{\hat{h}_i})^2 ]\\
	&+ \sum_{i=0}^{S^2}\sum_{j=0}^B \mathbb{1}_{ij}^{obj}(C_i - \hat{C}_i)^2 + \lambda_{noobj}\sum_{i=0}^{S^2}\sum_{j=0}^B \mathbb{1}_{ij}^{noobj}(C_i - \hat{C}_i)^2 \\
	&+ \sum_{i=0}^{S^2} \mathbb{1}_{i}^{obj}\sum_{c \in classes}(p_i(c) - \hat{p}_i(c))^2 \\
	\end{align}
	\fi
	
	\begin{equation}
	\mathcal{L} = \lambda_{loc}\mathcal{L}_{loc} + \lambda_{obj}\mathcal{L}_{obj} + \lambda_{noobj}\mathcal{L}_{noobj} + \lambda_{class}\mathcal{L}_{class}
	\end{equation}
	where $\mathcal{L}_{loc}$ is the target for bounding box regression, $\mathcal{L}_{obj}$ the loss where a object is present, $\mathcal{L}_{noobj}$ the loss where there is no object and $\mathcal{L}_{class}$ the classification loss. $\lambda$ are trade-off parameters between the multiple targets.
	
	For a single class prediction this can be simplified to:
	
	\begin{equation}
	\mathcal{L} = \lambda_{loc}\mathcal{L}_{loc} + \lambda_{obj}\mathcal{L}_{obj} + \lambda_{noobj}\mathcal{L}_{noobj}
	\end{equation}
	
	The object loss is defined as:
	
	\begin{equation}
		\mathcal{L}_{obj} = \sum_{i=0}^{S^2}\sum_{j=0}^B \mathbb{1}_{ij}^{obj}(\log(1+\exp(-o_{ij} \cdot \hat o_{ij}))
	\end{equation}
	where $o_{ij}$ is a softmax activation assigned to anchor box $i$,$j$,$\hat o_{ij}$ the ground truth label assigned to that box, 1 for object and -1 for no object.  $\mathbb{1}_{ij}^{obj}$ is 1 if the anchor box at $i$,$j$ is responsible to predict a certain object and 0 otherwise. The responsibility is determined by \ac{IoU} with a ground truth box. The box with the highest \ac{IoU} with the ground truth box gets assigned responsible.\todo{double check}
	
	The noobject loss is defined vice versa but triggered by the $\mathbb{1}_{ij}^{noobj}$ binary variable.
	
	The localization target is defined as:
	
	\begin{equation}
		\mathcal{L}_{loc} = \sum_{i=0}^{S^2}\sum_{j=0}^B \mathbb{1}_{ij}^{obj}[(x_{ij}-\hat{x}_{ij})^2 + (y_i-\hat{y}_{ij})^2  + (\sqrt{w_{ij}}-\sqrt{\hat{w}_{ij}})^2 +(\sqrt{h_{ij}}-\sqrt{\hat{h}_{ij}})^2 ]
	\end{equation}
	where $x$,$y$ are the center coordinates and $w$,$h$ are the bounding box width and height. $\mathbb{1}_{ij}^{obj}$ is 1 if the set of output nodes at $i$,$j$ is responsible to predict a certain object and 0 otherwise. 
	
	\section{Reducing Inference Time}
	
	A major drawback of \acp{CNN} is their huge computational requirements. For example a state-of-the-art Computer Vision model \cite{He2015} requires 11.3 billion floating point operations \cite{Tschannen2017}. For a device with computational limitations like an \ac{MAV} this is prohibitive. Furthermore, a perception system on a \ac{MAV} usually contains of multiple subsystems. Hence, a fast reaction time can be more important than an accurate detection/outbalanced by the filter etc.
	
	This
	
	The research question of this chapter is stated as:
	
	\begin{center}
		\textbf{What are the trade-off's between detection performance $m$ and inference time $t$ when a detection model is integrated on a embedded computing platform?}
	\end{center}
	
	The question is answered on a theoretical level by using the total number of \ac{Multiply-Adds} $N_O$ as an indication for the inference time of the model. However, as also stated by \todoref{others} $N_O$ is not necessarily directly related to $t$. On a computing platform $t$ also depends on:
	
	\begin{enumerate}
		\item whether several operations can be executed in parallel,
		\item the memory usage of the operations, the kind of operation e.g. floating point or integer
		\item the particular low level implementation of the model
	\end{enumerate} 
	
	Hence, in addition to $N_0$ also the actual inference time of the model is measured on a particular computing platform.
	
	The chosen hardware is a Jevois Smart Camera \todoref{jevois}. The platform is developed for vision applications and provides a 4 Core CPU, as well as a small GPU \todo{more info}. That's why it is perfectly suitable for integrating in lightweight \acp{MAV} or other robotic applications.
	
	The rest of the chapter is organized as follows: \autoref{sec:tradeoff:related} discusses relevant related work. Based on the gained insights \autoref{sec:tradeoff:hypothesis} formulates several hypotheses to be investigated. \autoref{sec:tradeoff:experiments} outlines the experiments conducted to evaluate the formulated hypotheses. \autoref{sec:tradeoff:results} describes the obtained results. \autoref{sec:tradeoff:conclusion} discusses the results and answers the research question.
	