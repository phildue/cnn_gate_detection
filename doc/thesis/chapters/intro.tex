\chapter{Introduction}
\label{sec:intro}

\acp{MAV} are an emerging technology that potentially can be used in a wide range of consumer, industrial and safety applications. For exampled \ac{MAV} are used to deliver medicine \todoref{https://www.cnet.com/news/zipline-new-delivery-drones-fly-medical-supplies-faster-farther/}, fight fires \todoref{https://www.nbcnews.com/mach/science/drones-are-fighting-wildfires-some-very-surprising-ways-ncna820966} or find survivors in disaster situations \todoref{https://www.titech.ac.jp/english/news/2017/040159.html}.

While currently a human pilot is still necessary in most applications research is conducted to enable the autonomous flight of \acp{MAV}. ...

A major challenge of autonomous flight is the accurate determination of the current position. As the system is highly dynamic, the position can change rapidly and on-board sensors like \acp{IMU} suffer from a lot of noise. External infrastructure like GPS and optical tracking systems can provide more accurate position determination but there is no guarantee that such systems are present in real world applications. Cameras on the other hand are cheap and lightweight and there-forth one of the most reliable sensors when it comes to on-board, global position determination.

The high-dimensional signal obtained from the camera is processed by computer vision algorithms running on the \ac{MAV}'s microprocessor. Within the field of Computer Vision, deep learning based algorithms have been pushing state of the art results tremendously after a long time of almost no improvements\todoref{alexnet ..}. The reason anticipated to be responsible for the performance boost is the flexibility of deep neural networks and the fact that a whole detection pipeline from feature extraction to classification and localization can be integrated into one model and trained directly on the task.\todoref{cite}

One main drawback of these \acp{CNN} is the immense amount of data and computational resources required to train all their parameters. Only when faster processing technologies evolved and the Internet simplified collecting, distributing and annotating large amounts of training examples, the potential of \acp{CNN} could be exploited \todoref{sth from gartner?} and led to the tremendous performance boost.

Hence, the power of state-of-the art object detection arises from the complexity of real-world objects that can be efficiently represented by \acp{CNN} when trained with large amounts of annotated examples.


This scenario imposes strong constraints on software systems as computational resources like memory and processing speed are very limited. In addition does less computation not only prolong the battery life of a \ac{MAV} but also allows more lightweight platforms and thus more aggressive flight maneouvres.

The field that is concerned with the processing of visual signals is Computer Visin.

A particularly challenging example of the described scenario is the \ac{IROS} 2018 Autonomous Drone Race. Within this race court several metal gates are placed and need to be passed one after another. The race allows engineers and scientists to evaluate their algorithms in a real world competitive environment.

The gates in the race court can be used

Object detection has been an intensively studied area within computer vision. The determination of what kind of objects we see where in an image is an everyday human task, that machines still have a hard time at solving.

\todo{paragraph about how learning based methods usually perform better than manually crafted models}


However, there are applications where each of the above is only available to a limited extent. For example mobile phones, robots and \acp{MAV} need to exploit their resources efficiently. Not only since saving energy allows for a longer lifetime but also because these systems usually need to meet real-time constraints.

Therefore, reducing the computational costs of deep neural networks has been widely addressed by the research community \todoref{Mobilnet, Quantized nets etc}. However, the majority of the publications still addresses network architectures with resource requirements that are prohibitive for \acp{MAV}. In contrast, DroNet \cite{Kyrkou2018} is a network architecture particular targeted to object detection on aerial images from \acp{MAV}. However, as this thesis shows the proposed method can not be transferred to first person view cameras (?) where a larger variety in scales is to be expected.

This work addresses a particularly challenging example of object detection from a FPV monocular camera on \acp{MAV}: Gate Detection at the IROS 2018 Autonomous Drone Race. Within this race court several coloured metal gates are placed and need to be passed one after another as fast as possible. Hence, the more lightweight the algorithm can be executed, the less computational resources are required, the lighter the \ac{MAV} can be build and the more aggressive manoeuvres can be flown. On the other hand if the method is too inaccurate, the drone can miss a gate and is likely to loose the race or even crash.

Due to these constraints previous methods for this application rely on manually engineered computer vision techniques e.g.\todoref{snake gate} as they are computationally much cheaper than state-of-the art object detection methods. However, these methods tend to be little robust to changes in illumination or object variance. That is why this thesis investigates a learning based approach for the detection of wire frame objects.

\todoref{koreans} use a \acp{CNN}-based gate detection method but rely with Jetson TX1 on a fast but heavy (XXg) computational platform. This work uses a Jevois Smart Camera \todoref{jevois} as target platform. The camera weighs XX g and contains 4 CPUs as well as a GPU \todo{elaborate}.

The class of objects considered poses particular challenges to an object detection system. For example the object can cover a large area of the input image while the majority of the area is still background or potentially another object. Furthermore does the object only consist of quite simple shapes like edges and corners. These object class is defined as wire frame objects. A full definition is given in \autoref{sec:object_detection}.

Machine learning based object detection assumes that a general concept of the object of interest can be learned from a limited set of annotated examples. However, \todo{why?} to this end there is no publicly available training set for wire frame objects. Instead the use of synthetic data for training object detection is studied. In particular it is studied how data generation can support the development of a lightweight \acp{CNN}-architecture.

\subsection*{Research Question}

The research question of this work is formulated as follows:
\begin{center}
	\textbf{How can a model for object detection of wire frame objects on \acp{MAV} be learned from synthetic data?}
\end{center}


This question is split into multiple questions that address individual parts of the topic:

\begin{itemize}
	\item How can data be generated to train a detection model for wire frame object detection on \acp{MAV}?
	\item How can a detection model represent wire frame objects?
	\item How can the inference time of a object detector be optimized for the application on a micro-air vehicle?
	\item Can the gained insights be used to build a lightweight and robust detection model for wire frame objects to be applied in autonomous drone racing?
\end{itemize}

Assumptions:
- There is a concept within the images of the race court that is consistent across all images and that can be generalized
- This concept can be extracted from annotated examples

The remaining parts of this thesis are structures as follows: \autoref{sec:evaluation} describes the metrics and systems used for evaluation.\\
 \autoref{sec:training}, \autoref{sec:object_detection} and \autoref{sec:tradeoff} address the individual research questions. Each chapter contains an introduction to the topic and experiments that have been carried out. \autoref{sec:training} describes methods to learn with limited availability of training data. It concludes with the datasets used for the remaining parts of this thesis.  \autoref{sec:object_detection} describes object detection and evaluates current methods in the application for wire frame objects.
\autoref{sec:tradeoff} illustrates and evaluates measures to reduce computations.
\autoref{sec:method} describes the method proposed in this work.\\
\autoref{sec:disc} discusses the overall results and formulates a conclusion.
