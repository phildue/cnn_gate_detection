\chapter{Discussion}

In this work we investigated a learning based approach for the detection of \acp{EWFO} on \acp{MAV}. The research was motivated by several drawbacks of the manual crafted detection method SnakeGate. The aim was to investigate whether a learning based Object Detector is more robust against, occlusion, out of view and changes in illumination. Our results show how the deep learning based detector outperforms SnakeGate especially in the cases of occlusion and out of view. The deep learning based detector can detect objects even when only 30\% of the object is visible or when backlight leads to strong changes in colour appearance.

Yet the deep learning based detector introduces its own drawbacks. For example the bounding boxes are generally less accurate than of SnakeGate. We assume that the reason is the general structure of \ac{Yolo}. \acp{CNN} collect "shallow" low level image features and combine them to a more deep representation of the image. Pooling layers reduce the spatial resolution to keep the number of computations tracktable, however thereby also local information about the features gets lost. In the final layers information is present which features are present in that part of the image, however it is not clear where they come from. 

This not only leads loss in localization accuracy but also to lack of transparency. In some scenarios a clearly visible gate is not detected by the \acp{CNN}. In this case it is hard to find out what part of the input image led to this wrong decision. In contrast for a simple algorithm such as  \textit{SnakeGate} it is clear at all times which input information led to a decision.

 Future work should address how to reflect back from the deep representation to the low level features.

A main argument for deep learning detectors is the fact that they can be trained on any kind of object and thus make feature engineering unnecessary. Furthermore, the learned representation are often much better than the features crafted manually. A drawback is the computational requirements of \acp{CNN}. For this work no training data was available and the computational requirements were limited. By implementing a data generation pipeline and refining the architecture we could show how the deep learning based method outperforms the manually crafted one. However, this process was a vast amount of work and yet we have a severe drop in peformance between the simulated and the real data. Hence, we have to wonder whether it would have not been more fruitful to invest time in feature engineering based on real data. It is questionable whether this is method would still perform better than the deep learning method. And yes for a new object it would required to be changed. But it would lead to a more transparent detector.
\todo{deep detector can be better extended but we loose track of whats going on, deep learning makes sense with the appropriate hardware and the appropriate data}