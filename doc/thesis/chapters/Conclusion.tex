\chapter{Conclusion \& Future Work}
\label{sec:conclusion}
This work investigated the detection of \acp{EWFO} on \ac{MAV} using a \ac{CNN}. In this section a final discussion is given and a conclusion is derived. Furthermore, the research questions are answered and possible future work is discussed.

This research was motivated by the promising results of Deep Learning based Object Detectors and several drawbacks of a manual crafted algorithm for the detection of racing gates in \ac{MAV} races. As the manually tuned features prove to be sensitive to light changes as well as to object occlusion the aim was to investigate a more robust method. The experiments show an improvement of performance compared to the baseline of 

 The aim was to investigate whether a learning based Object Detector is more robust against, occlusion, out of view and changes in illumination. Our results show how the deep learning based detector outperforms \textit{SnakeGate} especially in the cases of occlusion and out of view. The deep learning based detector is able to detect objects even in difficult lighting conditions.

Yet the deep learning based detector introduces its own drawbacks. For example the bounding boxes are generally less accurate than of SnakeGate. We assume that the reason is the general structure of \ac{Yolo}. \acp{CNN} collect "shallow" low level image features and combine them to a more deep representation of the image. Pooling layers reduce the spatial resolution to keep the number of computations tracktable, however thereby also local information about the features gets lost. In the final layers information is present which features are present in that part of the image, however it is not clear where they come from. 

This not only leads loss in localization accuracy but also to lack of transparency. In some scenarios a clearly visible gate is not detected by the \acp{CNN}. In this case it is hard to find out what part of the input image led to this wrong decision. In contrast for a simple algorithm such as  \textit{SnakeGate} it is clear at all times which input information led to a decision.

Future work should address how to reflect back from the deep representation to the low level features.

A main argument for deep learning detectors is the fact that they can be trained on any kind of object and thus make feature engineering unnecessary. Furthermore, the learned representation are often much better than the features crafted manually. A drawback is the computational requirements of \acp{CNN}. For this work no training data was available and the computational requirements were limited. By implementing a data generation pipeline and refining the architecture we could show how the deep learning based method outperforms the manually crafted one. However, this process was a vast amount of work and yet we have a severe drop in peformance between the simulated and the real data. Hence, we have to wonder whether it would have not been more fruitful to invest time in feature engineering based on real data. It is questionable whether this is method would still perform better than the deep learning method. And yes for a new object it would required to be changed. But it would lead to a more transparent detector.
\todo{deep detector can be better extended but we loose track of whats going on, deep learning makes sense with the appropriate hardware and the appropriate data}

\begin{enumerate}
	\item[\textbf{RQ1}]How can data be generated to train an object detector for \ac{EWFO} detection on a \acp{MAV}?
	
	In the experiments it could be seen how the detector is sensitive to overfit to environmental conditions present in the training set. When testing a detector in a different simulated environment than the test set the performance deteriorates between 30\% and 70\%. It was further investigated how to make the detector more invariant against such environmental changes. By pasting the object on backgrounds of the Pascal VOC dataset a larger variance in backgrounds was introduced. However, this led to an artificial training set where light conditions between fore- and background did not align. Hence, this method was compared to creating more synthetic environments with a graphical engine. Although less background variance is present with this method, light conditions and background align better with the object. It could be seen how using the graphical engine leads to a better performance than pasting the object on backgrounds of a dataset. We conclude that a realistic modelling of light conditions is more important than only a high variance in background.
	
	When a wide range of view angles is introduced in training and test set, the precision drops particularly for larger objects. It seems the detector has difficulties learning the detection from many angles. Better performance can be achieved by reducing the number of view angles in the training set. As this creates the question how to create realistic view points, we propose to simulate a flight through a race court. This way the created samples resemble the real world better. Even on unseen race courts the detector achieves a precision of 70\% compared to the 20\% achieved by the network trained with \textit{Random Placement}. 
	
	In order to transfer the detector to the real world, we find that image augmentation is crucial. Particularly modelling distortion improved the result on the real data. Yet there remains a reality gap between the results obtained in simulation and on real data. We cannot fully resolve whether this is because of the complexity of the real data or whether there are certain properties missing in the data generation process. Future work could address this issue by including real data in the training process. If this improves the results significantly the problem is likely because of a reality gap. Otherwise, there might be a more fundamental problem in the chosen detector/complexity of the test set.
	

	\item[\textbf{RQ2}]What kind of architecture is suitable to detect \acp{EWFO} on \acp{MAV}?
	
	By augmenting the empty part of the object with artificial structures, the detection of an \ac{EWFO} could be compared to a more solid object. It could be seen that this makes the detection easier as the network exploits the added structure. 
	
	For empty objects the detection proves more difficult especially in the more challenging environment of an \ac{MAV} race. At most 51\% average precision could be achieved. The results show that a shallow network of 9 layers performs equally well than a network with 15 layers. Further reducing depth gradually reduces performance from 51\% to 35\%. When reducing the width of a network with 9 layers it can be seen how the performance slowly deteriorates from 51\% to 38\%  to a fraction $\frac{1}{16}$ of its original size. 
		
\end{enumerate}



