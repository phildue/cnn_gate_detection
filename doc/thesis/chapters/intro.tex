\chapter{Introduction}
\label{sec:intro}

\acp{MAV} are an emerging technology that potentially can be used in a wide range of consumer, industrial and safety applications. For exampled \ac{MAV} are used to deliver medicine \todoref{https://www.cnet.com/news/zipline-new-delivery-drones-fly-medical-supplies-faster-farther/}, fight fires \todoref{https://www.nbcnews.com/mach/science/drones-are-fighting-wildfires-some-very-surprising-ways-ncna820966} or find survivors in disaster situations \todoref{https://www.titech.ac.jp/english/news/2017/040159.html}.

While currently a human pilot is still necessary in most applications research is conducted to enable the autonomous flight of \acp{MAV}. ...

A major challenge of autonomous flight is the accurate estimation of the \ac{MAV}'s state and within its environment. The system is highly dynamic so position and orientation can change rapidly. At the same time motor vibrations cause a lot of noise and make on-board sensors like \acp{IMU} an unreliable source of information. External infrastructure like GPS and optical tracking systems can provide more accurate measurements but there is no guarantee that such systems are present in real world applications. Cameras on the other hand are cheap and lightweight which makes them a popular choice as sensor for on-board state estimation.

Yet the signal delivered by the camera is high dimensional data that can not directly be interpreted as position or orientation measurement. Further processing by computer vision algorithms is  required to interpret the image and extract relevant information.

In recent years deep learning based methods have emerged as the predominant choice for almost any vision task. Several experiments have shown how these methods outperform manually crafted and traditional machine learning based methods in a lot of examples.

The hereby used \acp{CNN} are designed in an hierarchical way, using multiple layers that are evaluated sequentially enabling to model highly non-linear functions. Although this design is assumed to be the reason for their superior performance, it also leads to immense requirements in computational resources. The deployment of deep learning based vision systems on robotic devices that have limited processing power and need to follow hard real-time requirements is still an open challenge. 

This work addresses one example of image processing from a monocular \ac{FPV} camera on a \ac{MAV}: Gate detection at the \acp{IROS} 2018 Autonomous Drone Race. Within the race court several metal gates are placed and need to be passed one after another. The detection of these gates can be formulated as object detection problem and state-of-the-art object detectors can be applied. However, the type of object poses a particular challenge for a vision system. The object consists only of small edges and corners, which are spread over large distances in the image while a majority of the area is occupied by background. The detection of these particular objects is described in \autoref{sec:object_detection}. 

Without an accurate detection of the racing gate, the \ac{MAV} is not able to determine its current position and thus to complete the race court. On the other hand, with a more lightweight algorithm less computational resources are required and a lighter \ac{MAV} can be built. This allows faster and more aggressive trajectories as well as longer battery live. Hence, the trade-off between accuracy and inference speed is of particular interest for this application and is addressed in \autoref{sec:trade-off}.

Another drawback of deep-learning based methods is the requirement of a lot of annotated examples which are not available for every application. \todo{how do people deal with that}


\subsection*{Research Question}

The research question of this work is formulated as follows:
\begin{center}
	\textbf{How can a model for object detection of wire frame objects on \acp{MAV} be learned from synthetic data?}
\end{center}


This question is split into multiple questions that address individual parts of the topic:

\begin{itemize}
	\item How can data be generated to train a detection model for wire frame object detection on \acp{MAV}?
	\item How can a detection model represent wire frame objects?
	\item How can the inference time of a object detector be optimized for the application on a micro-air vehicle?
	\item Can the gained insights be used to build a lightweight and robust detection model for wire frame objects to be applied in autonomous drone racing?
\end{itemize}

Assumptions:
- There is a concept within the images of the race court that is consistent across all images and that can be generalized
- This concept can be extracted from annotated examples

The remaining parts of this thesis are structures as follows: \autoref{sec:evaluation} describes the metrics and systems used for evaluation.\\
 \autoref{sec:training}, \autoref{sec:object_detection} and \autoref{sec:tradeoff} address the individual research questions. Each chapter contains an introduction to the topic and experiments that have been carried out. \autoref{sec:training} describes methods to learn with limited availability of training data. It concludes with the datasets used for the remaining parts of this thesis.  \autoref{sec:object_detection} describes object detection and evaluates current methods in the application for wire frame objects.
\autoref{sec:tradeoff} illustrates and evaluates measures to reduce computations.
\autoref{sec:method} describes the method proposed in this work.\\
\autoref{sec:disc} discusses the overall results and formulates a conclusion.
